scraper-exemptions:
  schedule:
    crontab: "0 */4 * * *"

  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-exemption-urls
    # get the main HTML page of the exemptions search
    - run: add_resource
      parameters:
        name: mr-gov-il-search-exemption-messages
        url: https://www.mr.gov.il/ExemptionMessage/Pages/SearchExemptionMessages.aspx
        format: txt
    # download it (using tzabar runner which does some magic that bypasses network security)
    - run: stream_remote_resources
      runner: tzabar
    # parse all the publisher ids from the main search page
    - run: add_publishers_resource
      parameters:
        input_resource: mr-gov-il-search-exemption-messages
        tender_type: exemptions
    - run: throttle
      parameters:
        sleep-seconds: 0.25
#         log-interval-seconds: 0
    # go over each publisher and get urls for all exemptions related to this publisher
    # also adds tender_type column - which is needed as all tenders are on same table
    - run: add_publisher_urls_resource
      parameters:
        tender_type: exemptions
        output_resource: exemptions
      runner: tzabar
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/scraper-exemptions

scraper-office:
  schedule:
    crontab: "0 */4 * * *"

  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-office-urls
    # get the main HTML page of the office tenders search
    - run: add_resource
      parameters:
        name: mr-gov-il-search-office-tenders
        url: https://www.mr.gov.il/OfficesTenders/Pages/SearchOfficeTenders.aspx
        format: txt
    # download it (using tzabar runner which does some magic that bypasses network security)
    - run: stream_remote_resources
      runner: tzabar
    # parse all the publisher ids from the main search page
    - run: add_publishers_resource
      parameters:
        input_resource: mr-gov-il-search-office-tenders
        tender_type: office
    - run: throttle
    # go over each publisher and get urls for all office tenders related to this publisher
    # also adds tender_type column - which is needed as all tenders are on same table
    - run: add_publisher_urls_resource
      parameters:
        tender_type: office
        output_resource: office
      runner: tzabar
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/scraper-office

scraper-central:
  schedule:
    crontab: "0 */4 * * *"
  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-central-urls
    - run: throttle
    - run: add_central_urls_resource
      runner: tzabar
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/scraper-central

scraper:
  dependencies:
    - pipeline: ./procurement/tenders/scraper-exemptions
    - pipeline: ./procurement/tenders/scraper-office
    - pipeline: ./procurement/tenders/scraper-central

  pipeline:
    - run: load_resource
      parameters:
        resource: exemptions
        url: /var/datapackages/procurement/tenders/scraper-exemptions/datapackage.json
    - run: load_resource
      parameters:
        resource: office
        url: /var/datapackages/procurement/tenders/scraper-office/datapackage.json
    - run: load_resource
      parameters:
        resource: central
        url: /var/datapackages/procurement/tenders/scraper-central/datapackage.json
    - run: stream_remote_resources
    - run: concatenate
      parameters:
        target:
          name: tender-urls
        fields:
          id: []
          url: []
          tender_type: []
    # adds is_new column which indicates whether item already exists in DB or not (based on publication id and tender_type)
    - run: check_existing
      parameters:
        db-table: procurement_tenders
    # parse the data for each exemption
    - run: throttle
      parameters:
        sleep-seconds: 1
    # download the data from pages which don't exist in DB (is_new == False)
    - run: download_pages_data
      runner: tzabar
    - run: parse_page_data
      runner: tzabar
      parameters:
        output_resource: tenders
    - run: set_types
      parameters:
        resources: tenders
    # update the SQL table (based on the primary keys defined in the schemas)
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tenders:
            mode: update
            resource-name: tenders
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/scraper

all:
  title: Load all tenders data from DB to flat file

  schedule:
    crontab: "0 * * * *"

  dependencies:
    - pipeline: ./procurement/tenders/scraper

  pipeline:
    - run: add_metadata
      parameters:
        name: "procurement-tenders"
    - run: add_sql_resource
      parameters:
        datapackage: /var/datapackages/procurement/tenders/scraper/datapackage.json
        fields:
          - name: claim_date
            format: "%Y-%m-%dT%H:%M:%S"
        resource: tenders
        table: procurement_tenders
    - run: stream_remote_resources
    - run: set_types
      parameters:
        types:
          tender_id:
            constraints:
              required: true
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/all

processed:
  dependencies:
    - pipeline: ./procurement/tenders/all

  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-processed
    # Load scraped tenders
    - run: load_resource
      parameters:
        url: /var/datapackages/procurement/tenders/all/datapackage.json
        resource: tenders
    # Fingerprint exemption suppliers
    - run: fingerprint
      parameters:
        resource-name: tenders
        source-field: supplier
        source-id-field: supplier_id
    # Set types for ES
    - run: set_types
      parameters:
        types:
          description:
            es:title: true
          documents:
            es:itemType: object
            es:schema:
              fields:
                - {name: link, type: string}
                - {name: description, type: string}
                - {name: update_time, type: string}
    # add score field based on exemption amount and volume
    - run: calc-score-volume
    - run: set_primary_key
      parameters:
        tenders:
          - publication_id
          - tender_type
          - tender_id
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tenders_processed:
            mode: update
            resource-name: tenders
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/processed


