scraper-exemptions:
  schedule:
    crontab: "0 16 * * *"

  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-exemption-urls
    # get the main HTML page of the exemptions search
    - run: add_resource
      parameters:
        name: mr-gov-il-search-exemption-messages
        url: https://www.mr.gov.il/ExemptionMessage/Pages/SearchExemptionMessages.aspx
        format: txt
    # download it (using tzabar runner which does some magic that bypasses network security)
    - run: stream_remote_resources
      runner: tzabar
    # parse all the publisher ids from the main search page
    - run: add_publishers_resource
      parameters:
        input_resource: mr-gov-il-search-exemption-messages
        tender_type: exemptions
    - run: throttle
      parameters:
        sleep-seconds: 0.25
#         log-interval-seconds: 0
    # go over each publisher and get urls for all exemptions related to this publisher
    # also adds tender_type column - which is needed as all tenders are on same table
    - run: add_publisher_urls_resource
      parameters:
        tender_type: exemptions
        output_resource: exemptions
        db-table: procurement_tender_urls
      runner: tzabar
    - run: set_primary_key
      parameters:
        exemptions:
          - url
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tender_urls:
            resource-name: exemptions
            mode: update

scraper-office:
  schedule:
    crontab: "0 16 * * *"

  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-office-urls
    # get the main HTML page of the office tenders search
    - run: add_resource
      parameters:
        name: mr-gov-il-search-office-tenders
        url: https://www.mr.gov.il/OfficesTenders/Pages/SearchOfficeTenders.aspx
        format: txt
    # download it (using tzabar runner which does some magic that bypasses network security)
    - run: stream_remote_resources
      runner: tzabar
    # parse all the publisher ids from the main search page
    - run: add_publishers_resource
      parameters:
        input_resource: mr-gov-il-search-office-tenders
        tender_type: office
    - run: throttle
    # go over each publisher and get urls for all office tenders related to this publisher
    # also adds tender_type column - which is needed as all tenders are on same table
    - run: add_publisher_urls_resource
      parameters:
        tender_type: office
        output_resource: office
        db-table: procurement_tender_urls
      runner: tzabar
    - run: set_primary_key
      parameters:
        office:
          - url
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tender_urls:
            resource-name: office
            mode: update

scraper-central:
  schedule:
    crontab: "0 16 * * *"
  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-central-urls
    - run: throttle
    - run: add_central_urls_resource
      runner: tzabar
    - run: set_primary_key
      parameters:
        central:
          - url
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tender_urls:
            resource-name: central
            mode: update
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/scraper-central

scraper:
  dependencies:
    - pipeline: ./procurement/tenders/scraper-exemptions
    - pipeline: ./procurement/tenders/scraper-office
    - pipeline: ./procurement/tenders/scraper-central

  schedule:
    crontab: "0 */4 * * *"

  pipeline:
    - run: add_sql_resource
      parameters:
        datapackage: /var/datapackages/procurement/tenders/scraper-central/datapackage.json
        resource: central
        table: procurement_tender_urls
    - run: stream_remote_resources
    - run: concatenate
      parameters:
        target:
          name: tender-urls
        fields:
          id: []
          url: []
          tender_type: []
    - run: manage-revisions
      parameters:
        resource-name: tender-urls
        db-table: procurement_tenders
        key-fields: ['url']
        db-key-fields:
          - page_url
        hash-fields: []
    # - run: sample
    - run: parse_page_data
      runner: tzabar
    # - run: sample
    - run: set_types
      parameters:
        resources: tenders
    - run: manage-revisions
      parameters:
        resource-name: tenders
        db-table: procurement_tenders
        key-fields:
          - page_url
    # - run: sample
    # update the SQL table (based on the primary keys defined in the schemas)
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tenders:
            mode: update
            resource-name: tenders
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/scraper

all:
  title: Load all tenders data from DB to flat file

  dependencies:
    - pipeline: ./procurement/tenders/scraper

  pipeline:
    - run: add_metadata
      parameters:
        name: "procurement-tenders"
    - run: add_sql_resource
      parameters:
        datapackage: /var/datapackages/procurement/tenders/scraper/datapackage.json
        fields:
          - name: claim_date
            format: "%Y-%m-%dT%H:%M:%S"
          - name: __last_updated_at
            format: "%Y-%m-%dT%H:%M:%S"
          - name: __last_modified_at
            format: "%Y-%m-%dT%H:%M:%S"
          - name: __created_at
            format: '%Y-%m-%dT%H:%M:%S'
        resource: tenders
        table: procurement_tenders
    - run: stream_remote_resources
    - run: set_types
      parameters:
        types:
          tender_id:
            constraints:
              required: true
    - run: dump.to_path
      parameters:
        out-path: /var/datapackages/procurement/tenders/all

processed:
  dependencies:
    - pipeline: ./procurement/tenders/all

  pipeline:
    - run: add_metadata
      parameters:
        name: procurement-tenders-processed
        title: כל המכרזים ובקשות הפטור ממכרז
    # Load scraped tenders
    - run: load_resource
      parameters:
        url: /var/datapackages/procurement/tenders/all/datapackage.json
        resource: tenders
    - run: delete_fields
      parameters:
        fields:
          -  __last_updated_at
          -  __last_modified_at
          -  __created_at
          -  __is_new
          -  __is_stale
          -  __staleness
          -  __next_update_days
          -  __hash
    - run: process_contracts      
    - run: extra_values      
    # Fingerprint exemption suppliers
    - run: fingerprint
      parameters:
        resource-name: tenders
        source-field: supplier
        source-id-field: supplier_id
    # Set types for ES
    - run: set_types
      parameters:
        types:
          description:
            es:title: true
          documents:
            es:itemType: object
            es:schema:
              fields:
                - {name: link, type: string}
                - {name: description, type: string}
                - {name: update_time, type: string}
    # add score field based on exemption amount and volume
    - run: calc-score-volume
    - run: set_primary_key
      parameters:
        tenders:
          - publication_id
          - tender_type
          - tender_id
    - run: dump.to_sql
      parameters:
        tables:
          procurement_tenders_processed:
            resource-name: tenders
            mode: update
    - run: allstar_dumper
      parameters:
        out-path: /var/datapackages/procurement/tenders/processed


